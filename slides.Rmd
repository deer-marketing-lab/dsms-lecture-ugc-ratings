---
title: "Social Media & User Generated Content"
subtitle: "Digital and Social Media Strategies"
author: "Lachlan Deer"
institute: "Tilburg University"
date: "Updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, metropolis, metropolis-fonts]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: font150

# Learning Goals for this Week

* Define User Generated Content and Social Media 
* Identify reasons for the growth of social media 
* Explain the causal link between UGC and demand 
* Describe how online reputation management by firms impacts their subsequent reputation 
* Identify the effect of fake reviews on product sales and consumer welfare 
* Describe how Regression Discontinuity Design facilitates estimating causal effects

---
# Social Media Matters!

> .font140[**Massive growth in social media use over the last two decades**]
* 2005: 9% of Internet users aged 18-29 used social media (Aral, 2020)

* 2021: 53.6 % of the *world's population* uses social media (Hootsuite, 2021)
    * That's 4.2 billion people! 
    * Average daily usage is approx. 2 and a half hours 


---
# Social Network Popularity Over Time

```{r, echo = FALSE, fig.align = "center"}
knitr::include_graphics("https://www.smartinsights.com/wp-content/uploads/2020/04/Growth-of-social-networks.png")
```

Image Source: Our World in Data, 2021 "[The rise of social media](https://ourworldindata.org/rise-of-social-media)" 

---
# Social Media Informs Purchasing

```{r, echo = FALSE, fig.align = "center", out.width="75%"}
knitr::include_graphics("https://www.smartinsights.com/wp-content/uploads/2020/04/How-social-media-informs-purchase-decisions.png")
```

Image Source: Global Web Index, 2021 "[Social media marketing trends in 2021](https://www.globalwebindex.com/reports/social)" 

---
class: .font160
# Some Useful Definitions

.font140[
**User Generated Content**: Content that is generated or created by an internet user who is a consumer of this information or content
]

.font140[
**Social Media**: The online platforms that host this content
]

* Think of these as the working definitions for our course

* People have a tendency to be use these terms relatively interchangeably 
  * (include me as one of the "people")

---
# Why Did Social Media Take off?

Three factors:

* **Digital Social Networks**
  * Structured information flow

* **Machine Intelligence**
  * Recommendations of friends and content over the network

* **Smartphones**
  * "Always on"
  * Feeds our social brain

---
class: font160
# Today's Topic Coverage


Reviews, Reputation and Revenue: The Case of Yelp.com

* [Luca (2016)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1928601)

Online Reputation Management: Estimating the Impact of Management Responses on Consumer Reviews

* [Proserpio & Zervas](https://doi.org/10.1287/mksc.2017.1043)

The Market for Fake Reviews

* [He, Hollenbeck & Proserpio (2022)](https://doi.org/10.1287/mksc.2022.1353)

Real-Time Brand Reputation Tracking Using Social Media 

* [Rust, Rand, Huang, Stephan, Brooks & Chabuk (2021)](https://doi.org/10.1177/0022242921995173) 
* (Recommended -- we won't cover this in class)

---
# Focus on the Authors 

.pull-left[

```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "https://www.hbs.edu/Style%20Library/api/headshot.aspx?id=602417"
knitr::include_graphics(url)
```
]

.pull-right[
**Michael Luca**

* Associate Prof at Harvard
* Research in Online Platforms and Reviews
* Value of Experiments:

```{r, echo = FALSE, fig.align = "center", out.width="50%"}
url <- "https://mit-press-us.imgix.net/covers/9780262542272.jpg?auto=format&w=298&dpr=1&q=20"
knitr::include_graphics(url)
```
]

---
# Focus on the Authors 

.pull-left[

```{r, echo = FALSE, fig.align = "center", out.width="70%"}
url <- "https://s.yimg.com/ge/labs/v1/uploads/Davide-Proserpio.jpeg"
knitr::include_graphics(url)
```
]

.pull-right[
**Davide Proserpio**

* Assistant Prof at U South California
* Sharing Economy (eg. Airbnb) 
* Online Trust and Reputation
]


---
class: inverse, center, middle

# Reviews, Reputation and Revenue: The Case of Yelp.com

---
class: font160
# Motivation 

**Strategic Question**: Do consumer reviews have causal impact on demand for experience goods

* **Experience goods**: some attribute (eg. quality) remains unknown until purchase 

Why relevant? 

* Review platforms prevalent, heavily used 
* But reviews noisy, difficult to interpret 
* And other mechanisms exist for solving info asymmetry 
  * Chain affiliation, Advertising, Expert reviews

---
class: font160
# How to do this? 

Running an experiment difficult / impossible 

* Recurring issue in UGC markets 

**Solution**: Exploit "jumps" in ratings due to Yelp's page design 

* Average Review Score for a restaurant is continuous [0 - 5] ... 
* But displayed as rounded to the nearest half star 
* "Similar" restaurants will be displayed with different star ratings
* We'll delve deeper soon ...

**Data**

* Yelp star rating and average star ratings over time 
* Restaurant revenue 
* Seattle, 2003 through 2009

---
# How Yelp Displays Ratings 

```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "figs/luca_yelp_halfpoints.png"
knitr::include_graphics(url)
```

---
class: font160
# Yelp Reviews & Revenue? 

.pull-left[ 

```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "figs/luca_yelp_revenue.png"
knitr::include_graphics(url)
```

]
.pull-right[

First Step: **Correlation between Yelp Ratings and Revenue?**

* One star increase associated with 5.4% increase in revenue 

Why can't we stop here? 

* Yelp rating may be correlated with other unobservable factors 
* That are correlated with revenue 

$\implies$ **Omitted Variable Bias**

]

---
# Rounding Ratings to Stars 

```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "figs/luca_rdd_rounding.png"
knitr::include_graphics(url)
```

---
class: font160
# Regression Discontinuity Design

Core Idea: **Natural Experiment** where **Treatment allocated based on a cutoff score**

In this case: 

* Restaurant A: Avg Score 4.24 $\rightarrow$ 4 star 
* Restaurant B: Avg Score 4.25 $\rightarrow$ 4.5 star 
* Treatment is the extra half star

But wait! 

* Aren't restaurants with a higher Avg Rating simply "better" ...
* ... And won't that be what we're estimating? 
* (And isn't that the problem with the simple regression!?)

---
class: font160
# Regression Discontinuity Design

**RDD focusses on the area right around the cutoff**

* So comparing restaurants with **very similar average scores** 

**Main Idea**: Within this group, it's **essentially random** whether you are **assigned 4 or 4.5 stars** 

* Think of this as "barely in" vs "barely out"
* These **restaurants should be almost identical** except one's star rating got rounded up
* Seems like a good control group!
* Remark: **Essentially random is an assumption**!
  * Good, very recent papers will show you that around the cutoff, observable characteristics of treatment and control units are not jumping around
  * And that there is no manipulation 


---
class: font160
# Main Results

```{r, echo = FALSE, fig.align = "center", out.width="60%"}
url <- "figs/luca_rdd_main.png"
knitr::include_graphics(url)
```

Estimates for half star ratings jump, normalized to one star changes 

$\implies$ **One star improvement leads to an approx 9% increase in revenue** 


---
class: font160
# Chain vs Independents 

```{r, echo = FALSE, fig.align = "center", out.width="60%"}
url <- "figs/luca_rdd_chains.png"
knitr::include_graphics(url)
```

**Yelp increases consumer's value of going to an independent restaurant** 

* Which translates into higher revenue 
* Luca points to this being due to consumers learning about quality

---
class: font160
# Crowding Out of Chains?

```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "figs/luca_rdd_crowd_out.png"
knitr::include_graphics(url)
```

**Chains experience decline in revenue relative to independent restaurants post-Yelp**

---
class: font160
# Takeaways

* Reviews have a positive, causal impact on demand 
  * As measured via a Regression Discontinuity Design  

* One star improvement leads to an approx 9% increase in revenue

* Effect holds for independent restaurants rather than chains 

* Chain restaurants decline in revenue after Yelp introduced 

$\implies$ Review websites alleviate information uncertainties about products & consumers respond to ratings

---
class: inverse, center, middle

# Management Responses to Online Reviews

---
class: font160
# Motivation 

**Strategic Question**: Do management responses to online reviews impact future ratings?

Why relevant? 

* Ratings matter for demand 
* Legal, endorsed by platforms (as opposed to review fraud)
* Widely adopted by managers 

Setting: 

* Hotel Industry (Trip Advisor and Expedia)
* Natural Experiment / Diff in Diff
  * The details to come...

---
class: font140
# The Natural Experiment

* **Treatment**: Managers respond to reviews on Trip Advisor
  * They can't on Expedia 
  * Treating management decision as a "suprise" (i.e. random shock) to future reviewers

* **Treatment Group:** Reviews of a Hotel on Trip Advisor

* **Control Group:**  Reviews of a Hotel on Expedia

* **Outcome Variable**: Star rating of reviews

* "Cross-platform": relative changed in star ratings between platforms after a reponse is written on Trip Advisor
  * Differences in level of ratings for same hotel on different sites not an issue ...
  * "Differenced out" in the Diff in Diff regression

---
class: font140
# Graphical Evidence

.pull-left[
```{r, echo = FALSE, fig.align = "center", out.width="90%"}
url <- "figs/pv_ashenfelterdip.png"
knitr::include_graphics(url)
```
]

.pull-right[

1. **Dip in relative ratings in the month before managers begin adopting responses** 
  * akin to an "[Ashenfelter Dip](https://www.google.com/search?q=ashenfelter+dip)"
  * Drop reviews left up to 30 days before 

2. **Relative increase in star ratings after responses begin** 
  * That appears permanent
]

---
class: font140
# Main Results 

.pull-left[
```{r, echo = FALSE, fig.align = "center", out.width="100%"}
url <- "figs/pv_xplatform_main.png"
knitr::include_graphics(url)
```
]
.pull-right[
Management Responses lead to an increase in star rating of 0.097 stars 

Is this a **big** effect?

* approx 3 percent increase on average Trip Advisor Rating
  * Hard to interpret ... 
* Translates to about 7.5% of the standard deviation in ratings 
  * Still hard to interpret ... 
  * But similar in magnitude to effect of good job training programs on wages 



]

.font70[**Never put t-statistics in parentheses on a regression table!**]

---
class: font150
# Visibility of Management Responses

.pull-left[
```{r, echo = FALSE, fig.align = "center", out.width="100%"}
url <- "figs/pv_xplatform_page_intuition.png"
knitr::include_graphics(url)
```
]
.pull-right[
**Do the responses need to be visible?**

Idea (intuitively):

* Reviewer 10 sees response on first page of TA 
* Reviewer 11 sees response on second page of TA 

Response more effective on Reviewer 10 than Reviewer 11
]


---
class: font150
# Visibility of Management Responses

.pull-left[
```{r, echo = FALSE, fig.align = "center", out.width="100%"}
url <- "figs/pv_xplatform_page.png"
knitr::include_graphics(url)
```
]
.pull-right[
**Effect is larger when responses are visible to the review writer**
]


---
class: font140
# Review Length Effects

```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "figs/pv_response_length.png"
knitr::include_graphics(url)
```

* More reviews after start responding
* Effect is larger when responses are visible to the review writer

--
# Takeaways 

* Responding to reviews increases future ratings 

* After adopting responses, ratings increase by approx 0.1 stars (out of 5)
  * About 7.5 percent of a standard deviation

* Effect larger when responses are likely visible to reviewer 
  * i.e. on first page  

* Also see more reviews, longer negative reviews 

---
class: inverse, center, middle

# The Market for Fake Reviews

---
class: font160
# Motivation 

**Strategic Question**: Do fake reviews have a causal effect on sales?

Why relevant? 

* Prevalent practice
* Matters for platforms and sellers 

Setting: 

* Products on Amazon, Fake Review Facebook Groups
* Natural Experiment / Diff in Diff
  * Details to come ...

---
# Fake Review Recruiting

```{r, echo = FALSE, fig.align = "center", out.width="100%"}
url <- "figs/hpp_recruiting.png"
knitr::include_graphics(url)
```

---
# Fake Reviews Influence Business Metrics

```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "figs/hpp_trends.png"
knitr::include_graphics(url)
```


```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "figs/hpp_trends_2.png"
knitr::include_graphics(url)
```

---
class: font160
# The Experiment 

Setting: Amazon undertakes large scale purge of (fake) reviews

**Treatment**: Recruiting fake reviews starts 

**Treatment Group**: Products on Amazon that did recruit fake reviews on Facebook

**Control Group**: Products on Amazon that did **not** recruit fake reviews on Facebook

**When?**Before** March 15 2020, focus on three weeks around that date

**Idea**: Purge of reviews impacts products who recruit fake reviews but not those that don't

---
class: font150
# Slide Title 

```{r, echo = FALSE, fig.align = "center", out.width="80%"}
url <- "figs/hpp_did_main.png"
knitr::include_graphics(url)
```

* Approx 10 percent increase in reviews after recruiting starts
* 31 % improvement in sales rank

---
class: font160
# Slide Title 

```{r, echo = FALSE, fig.align = "center", out.width="60%"}
url <- "figs/hpp_did_onestar.png"
knitr::include_graphics(url)
```

Share of one-star reviews increases after recruiting fake reviews stops

$\implies$ harmful to consumers

---
class: font160
# Takeaways

* Fake reviews increase number of reviews and sales rank 

* Harmful to consumers 

---
class: inverse, center, middle

# Recap

---
class: font160
# Summary

User Generated Content matters to consumers 

* User generated star ratings increase demand for products where quality is uncertain and erodes value of chains 

* When firms respond to reviews, leads to improved reputation  

* Fake reviews are prevalent, impact sales and decrease consumer welfare

---
# License & Citation

Suggested Citation:

```{r, engine='out', eval = FALSE}
@misc{deerdsms2022,
      title={"Digital and Social Media Strategies: Social Media and User Generated Content"},
      author={Lachlan Deer},
      year={2022},
      url = "https://github.com/tisem-digital-marketing/dsms-lecture-11-ugc"
}
```

<p style="text-align:center;"><img src="https://www.tilburguniversity.edu/sites/default/files/styles/large_width/public/image/Logo%20OSCT.png?itok=PqU9mw_l" alt="Logo" width = "200"></p>

This course adheres to the principles of the Open Science Community of Tilburg University. 
This initiative advocates for transparency and accessibility in research and teaching to all levels of society and thus creating more accountability and impact.

<p style="text-align:center;"><img src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" alt="Logo" width = "100"></p>
This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.